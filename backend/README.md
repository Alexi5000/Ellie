# Ellie Voice Receptionist - Backend

Node.js/Express backend API for the Ellie Voice Receptionist AI Assistant.

## ğŸ—ï¸ Architecture

### Technology Stack
- **Runtime**: Node.js 18+
- **Framework**: Express.js
- **Language**: TypeScript
- **Database**: Redis (caching & sessions)
- **Real-time**: Socket.IO
- **AI Services**: OpenAI (GPT-4, Whisper) + Groq

### Key Features
- **Voice Processing**: Speech-to-text and text-to-speech
- **AI Integration**: Dual AI provider with intelligent routing
- **Service Discovery**: Microservices architecture
- **Circuit Breaker**: Fault tolerance
- **Rate Limiting**: Redis-backed rate limiting
- **Caching**: Multi-tier caching strategy
- **Load Balancing**: Health-based routing
- **WebSocket**: Real-time communication
- **Monitoring**: Comprehensive logging and metrics

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ routes/              # API route handlers
â”‚   â”‚   â”œâ”€â”€ voice.ts        # Voice processing endpoints
â”‚   â”‚   â””â”€â”€ legal.ts        # Legal compliance endpoints
â”‚   â”œâ”€â”€ services/            # Business logic services
â”‚   â”‚   â”œâ”€â”€ voiceProcessingService.ts    # Voice I/O
â”‚   â”‚   â”œâ”€â”€ aiResponseService.ts         # AI integration
â”‚   â”‚   â”œâ”€â”€ serviceDiscovery.ts          # Service registry
â”‚   â”‚   â”œâ”€â”€ circuitBreaker.ts            # Fault tolerance
â”‚   â”‚   â”œâ”€â”€ cacheService.ts              # Caching layer
â”‚   â”‚   â”œâ”€â”€ rateLimitService.ts          # Rate limiting
â”‚   â”‚   â”œâ”€â”€ loadBalancer.ts              # Load balancing
â”‚   â”‚   â”œâ”€â”€ websocketHandler.ts          # WebSocket manager
â”‚   â”‚   â”œâ”€â”€ healthCheckService.ts        # Health monitoring
â”‚   â”‚   â”œâ”€â”€ legalComplianceService.ts    # Legal features
â”‚   â”‚   â”œâ”€â”€ sessionManager.ts            # Session management
â”‚   â”‚   â”œâ”€â”€ analyticsService.ts          # Analytics
â”‚   â”‚   â”œâ”€â”€ loggerService.ts             # Logging
â”‚   â”‚   â””â”€â”€ ...                          # Other services
â”‚   â”œâ”€â”€ types/               # TypeScript type definitions
â”‚   â”‚   â”œâ”€â”€ audio.ts        # Audio-related types
â”‚   â”‚   â”œâ”€â”€ conversation.ts # Conversation types
â”‚   â”‚   â”œâ”€â”€ errors.ts       # Error types
â”‚   â”‚   â”œâ”€â”€ websocket.ts    # WebSocket types
â”‚   â”‚   â””â”€â”€ express.d.ts    # Express extensions
â”‚   â”œâ”€â”€ utils/               # Utility functions
â”‚   â”‚   â””â”€â”€ errorHandler.ts # Error handling
â”‚   â”œâ”€â”€ test/                # Test files
â”‚   â”‚   â”œâ”€â”€ setup.ts        # Test configuration
â”‚   â”‚   â”œâ”€â”€ testHelpers.ts  # Test utilities
â”‚   â”‚   â””â”€â”€ *.test.ts       # Test files
â”‚   â””â”€â”€ index.ts             # Application entry point
â”œâ”€â”€ dist/                    # Compiled JavaScript (gitignored)
â”œâ”€â”€ scripts/                 # Utility scripts
â”œâ”€â”€ .env.example             # Environment template
â”œâ”€â”€ .env.test                # Test environment
â”œâ”€â”€ Dockerfile               # Docker configuration
â”œâ”€â”€ healthcheck.js           # Docker health check
â”œâ”€â”€ jest.config.js           # Jest configuration
â”œâ”€â”€ tsconfig.json            # TypeScript configuration
â”œâ”€â”€ package.json             # Dependencies
â””â”€â”€ README.md                # This file
```

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Redis 6.0+
- OpenAI API key
- Groq API key (optional)

### Installation

1. **Install dependencies**:
```bash
npm install
```

2. **Configure environment**:
```bash
cp .env.example .env
# Edit .env with your API keys
```

3. **Start Redis** (if not using Docker):
```bash
redis-server
```

4. **Run development server**:
```bash
npm run dev
```

The server will start at http://localhost:5000

### Docker Development

```bash
# From project root
npm run docker:up
```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file with the following:

```bash
# Server
NODE_ENV=development
PORT=5000
HOST=localhost
CORS_ORIGIN=http://localhost:3000

# API Keys
OPENAI_API_KEY=your_openai_api_key
GROQ_API_KEY=your_groq_api_key

# Redis
REDIS_URL=redis://localhost:6379

# Features
SERVICE_DISCOVERY_ENABLED=true
LOAD_BALANCING_STRATEGY=health_based
RATE_LIMIT_ENABLED=true
CACHE_ENABLED=true

# Logging
LOG_LEVEL=info
LOG_FORMAT=json
```

## ğŸ“š API Endpoints

### Voice Processing
- `POST /api/voice/process` - Process voice input
- `POST /api/voice/upload` - Upload audio file
- `GET /api/voice/tts/:text` - Text-to-speech

### Legal Compliance
- `POST /api/legal/disclaimer/accept` - Accept disclaimer
- `GET /api/legal/disclaimer/status` - Check disclaimer status

### Service Discovery
- `GET /services` - List all services
- `GET /services/health` - System health
- `GET /services/stats` - Service statistics

### Health & Monitoring
- `GET /health` - Health check
- `GET /api/analytics/stats` - System statistics

### WebSocket
- `WS /socket.io` - Real-time communication

## ğŸ§ª Testing

### Run Tests

```bash
# All tests
npm test

# Watch mode
npm run test:watch

# Specific test file
npm test -- voiceRoutes.test.ts

# With coverage
npm test -- --coverage
```

### Test Structure

- **Unit Tests**: Test individual services
- **Integration Tests**: Test API endpoints
- **Test Helpers**: Reusable test utilities in `src/test/testHelpers.ts`

### Test Environment

Tests use a separate `.env.test` file with mock API keys. See `docs/testing/BACKEND_TEST_ENVIRONMENT.md` for details.

## ğŸ—ï¸ Development

### Build

```bash
# Compile TypeScript
npm run build

# Output in dist/
```

### Run Production Build

```bash
npm run build
npm start
```

### Code Style

- TypeScript with strict mode
- ESLint for linting
- Prettier for formatting
- Follow existing patterns

## ğŸ” Key Services

### Voice Processing Service
Handles speech-to-text and text-to-speech using OpenAI Whisper and TTS.

### AI Response Service
Manages AI provider selection (OpenAI GPT-4 vs Groq) with intelligent routing based on query complexity.

### Service Discovery
Automatic service registration and discovery for microservices architecture.

### Circuit Breaker
Prevents cascading failures by monitoring service health and automatically opening/closing circuits.

### Cache Service
Multi-tier caching with Redis primary and in-memory fallback.

### Rate Limit Service
Redis-backed rate limiting with sliding window algorithm.

### Load Balancer
Intelligent request routing with multiple strategies:
- Round robin
- Least connections
- Health-based (default)

### WebSocket Handler
Manages real-time bidirectional communication for voice interactions.

## ğŸ“Š Monitoring

### Logging
- Structured JSON logging
- Correlation IDs for request tracking
- Multiple log levels (debug, info, warn, error)
- Log rotation and archival

### Health Checks
- Deep health monitoring
- Dependency health checks (Redis, AI services)
- Graceful degradation

### Analytics
- Usage statistics
- Performance metrics
- Error tracking
- Service discovery stats

## ğŸ”’ Security

### Features
- **Helmet**: Security headers
- **CORS**: Configurable cross-origin policies
- **Rate Limiting**: Prevent abuse
- **Input Validation**: Request validation
- **Error Handling**: Secure error responses

### Best Practices
- No sensitive data in logs
- API keys in environment variables
- Secure session management
- HTTPS in production

## ğŸ³ Docker

### Development
```bash
docker build -t ellie-backend:dev --target development .
docker run -p 5000:5000 ellie-backend:dev
```

### Production
```bash
docker build -t ellie-backend:prod --target production .
docker run -p 5000:5000 ellie-backend:prod
```

### Health Check
The Docker container includes a health check script (`healthcheck.js`) that verifies the server is responding.

## ğŸ“ˆ Performance

### Optimization Strategies
- Connection pooling (Redis)
- Response caching
- Circuit breakers for external services
- Load balancing
- Async/await patterns
- Efficient error handling

### Benchmarks
- Voice processing: ~2-5 seconds end-to-end
- Text processing: ~500ms-1s response time
- API throughput: 500+ requests/second
- WebSocket: 500+ concurrent connections

## ğŸ¤ Contributing

1. Follow the existing code structure
2. Add tests for new features
3. Update documentation
4. Run tests before committing
5. Follow TypeScript best practices

## ğŸ“„ Documentation

- **API Documentation**: See endpoint comments in route files
- **Service Documentation**: See JSDoc comments in service files
- **Test Documentation**: See `docs/testing/`
- **Development Guide**: See `docs/development/`

## ğŸ”„ Migration Notes

This is the primary active backend. A FastAPI (Python) migration experiment is archived in `docs/migration/backend-fastapi-reference/` for reference.

## ğŸ†˜ Troubleshooting

### Common Issues

**Port already in use**:
```bash
# Find process using port 5000
lsof -i :5000  # macOS/Linux
netstat -ano | findstr :5000  # Windows

# Kill the process or use a different port
```

**Redis connection failed**:
```bash
# Check if Redis is running
redis-cli ping

# Start Redis
redis-server
```

**API key errors**:
- Verify `.env` file exists
- Check API keys are valid
- Ensure no extra spaces in `.env`

**Test failures**:
- Check `.env.test` exists
- Verify mock services are configured
- Run tests in isolation

## ğŸ“ Support

- **Documentation**: Check `docs/` folder
- **Issues**: Create GitHub issue
- **Tests**: See `docs/testing/BACKEND_TEST_ENVIRONMENT.md`

---

**Version**: 1.0.0  
**License**: MIT  
**Maintained By**: Ellie Voice Receptionist Team
